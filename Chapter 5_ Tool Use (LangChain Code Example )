{"cells":[{"cell_type":"code","source":["import os\n","import asyncio\n","from typing import List\n","\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.tools import tool\n","from langchain.agents import create_tool_calling_agent, AgentExecutor\n","\n","# --- Configuration ---\n","# Ensure your GOOGLE_API_KEY environment variable is set.\n","try:\n","    # A model with function/tool calling capabilities is required.\n","    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)\n","    print(f\"‚úÖ Language model initialized: {llm.model_name}\")\n","except Exception as e:\n","    print(f\"üõë Error initializing language model: {e}\")\n","    llm = None\n","\n","\n","# --- Define a Tool ---\n","@tool\n","def search_information(query: str) -> str:\n","    \"\"\"\n","    Provides factual information on a given topic. Use this tool to find answers to questions\n","    like 'What is the capital of France?' or 'What is the weather in London?'.\n","    \"\"\"\n","    print(f\"\\n--- üõ†Ô∏è Tool Called: search_information with query: '{query}' ---\")\n","    # Simulate a search tool with a dictionary of predefined results.\n","    simulated_results = {\n","        \"weather in london\": \"The weather in London is currently cloudy with a temperature of 15¬∞C.\",\n","        \"capital of france\": \"The capital of France is Paris.\",\n","        \"population of earth\": \"The estimated population of Earth is around 8 billion people.\",\n","        \"tallest mountain\": \"Mount Everest is the tallest mountain above sea level.\",\n","        \"default\": f\"Simulated search result for '{query}': No specific information found, but the topic seems interesting.\"\n","    }\n","    result = simulated_results.get(query.lower(), simulated_results[\"default\"])\n","    print(f\"--- TOOL RESULT: {result} ---\")\n","    return result\n","\n","tools = [search_information]\n","\n","\n","# --- Create a Tool-Calling Agent ---\n","if llm:\n","    # This prompt template requires an `agent_scratchpad` placeholder for the agent's internal steps.\n","    agent_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", \"You are a helpful assistant.\"),\n","        (\"human\", \"{input}\"),\n","        (\"placeholder\", \"{agent_scratchpad}\"),\n","    ])\n","\n","    # Create the agent, binding the LLM, tools, and prompt together.\n","    agent = create_tool_calling_agent(llm, tools, agent_prompt)\n","\n","    # AgentExecutor is the runtime that invokes the agent and executes the chosen tools.\n","    # The 'tools' argument is not needed here as they are already bound to the agent.\n","    agent_executor = AgentExecutor(agent=agent, verbose=True)\n","\n","\n","    async def run_agent_with_tool(query: str):\n","        \"\"\"Invokes the agent executor with a query and prints the final response.\"\"\"\n","        print(f\"\\n--- üèÉ Running Agent with Query: '{query}' ---\")\n","        try:\n","            response = await agent_executor.ainvoke({\"input\": query})\n","            print(\"\\n--- ‚úÖ Final Agent Response ---\")\n","            print(response[\"output\"])\n","        except Exception as e:\n","            print(f\"\\nüõë An error occurred during agent execution: {e}\")\n","\n","    async def main():\n","        \"\"\"Runs all agent queries concurrently.\"\"\"\n","        tasks = [\n","            run_agent_with_tool(\"What is the capital of France?\"),\n","            run_agent_with_tool(\"What's the weather like in London?\"),\n","            run_agent_with_tool(\"Tell me something about dogs.\") # Should trigger the default tool response\n","        ]\n","        await asyncio.gather(*tasks)\n","\n","    if __name__ == \"__main__\":\n","        # Run all async tasks in a single event loop.\n","        asyncio.run(main())\n","\n","else:\n","    print(\"\\nSkipping agent execution due to LLM initialization failure.\")"],"outputs":[],"execution_count":null,"metadata":{"id":"1R7Oj2fTbMgb"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}